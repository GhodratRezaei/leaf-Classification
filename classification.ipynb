{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.10","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# Install the missing packages\n! pip install tensorflow-addons\n! pip install gdown\n! pip install zipfile\n\n# Import the libraries needed\nimport os\nimport numpy as np\nfrom   PIL import Image\nimport matplotlib.pyplot as plt\nimport random\nimport tensorflow as tf\nimport tensorflow_addons as tfa\nimport gdown\nfrom   tensorflow.keras.preprocessing import image_dataset_from_directory\nfrom   tensorflow.keras.applications import EfficientNetB4\n\n# Define some shortcuts\ntfk  = tf.keras\ntfkl = tf.keras.layers\n\n# Download and unzip the dataset\n! gdown --id 1mZqRi_NjuozRQdO3CzbKS4ve-erTRWuX\n! unzip dataset.zip\n\n# Download and unzip the image dataset\n! gdown --id 179XBNS5FU1dAZTOMqsA1_e1xgiGhlsxl\n! tar -xf noisy_student_efficientnet-b4.tar.gz\n\n# Download the noisy student efficientnet-b4 weights (state of the art pre-trained weights for this model). Convert them into a '.h5' model\n! gdown --id 1nnHTLskmwOyKWgEk7wcShKLSZ23eAFTH\n! python efficientnet_weight_update_util.py --model b4 --notop --ckpt ./noisy_student_efficientnet-b4/model.ckpt --o efficientnetb4_notop.h5\n\n# Definition and application of the random seed for reproducibility\nseed = 42\nrandom.seed(seed)\nos.environ['PYTHONHASHSEED'] = str(seed)\nnp.random.seed(seed)\ntf.random.set_seed(seed)\ntf.compat.v1.set_random_seed(seed)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Definition of the training folder, it will be useful later\ntraining_dir = 'training'\n\n# Plot example images from dataset\nlabels_list = ['Apple', 'Blueberry', 'Cherry', 'Corn', 'Grape', 'Orange', 'Peach', 'Pepper', 'Potato', 'Raspberry', 'Soybean', 'Squash', 'Strawberry', 'Tomato']\nnum_row     = len(labels_list)//2\nnum_col     = len(labels_list)//num_row\nfig, axes   = plt.subplots(num_row, num_col, figsize=(2*num_row,15*num_col))\n\nfor i in range(len(labels_list)):\n  if i < len(labels_list):\n    class_imgs = next(os.walk('{}/{}/'.format(training_dir, labels_list[i])))[2]\n    class_img  = class_imgs[0]\n    img        = Image.open('{}/{}/{}'.format(training_dir, labels_list[i], class_img))\n    ax         = axes[i//num_col, i%num_col]\n    ax.imshow(np.array(img))\n    ax.set_title('{}'.format(labels_list[i]))\n    \nplt.tight_layout()\nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Generation of a tf.data.Dataset from image files in a directory (both for training and validation)\n\ntrain_dataset = image_dataset_from_directory(\n                    directory        = training_dir,\n                    labels           = 'inferred',\n                    label_mode       = 'categorical',\n                    class_names      = labels_list,\n                    color_mode       = 'rgb',\n                    batch_size       = 64,\n                    image_size       = (256, 256),\n                    shuffle          = True,\n                    seed             = seed,\n                    validation_split = 0.2,\n                    subset           = 'training')\n\nval_dataset = image_dataset_from_directory(\n                    directory        = training_dir,\n                    labels           = 'inferred',\n                    label_mode       = 'categorical',\n                    class_names      = labels_list,\n                    color_mode       = 'rgb',\n                    batch_size       = 64,\n                    image_size       = (256, 256),\n                    shuffle          = True,\n                    seed             = seed,\n                    validation_split = 0.2,\n                    subset           = 'validation')\n\n# Buffered prefetching allows us to yield data from disk without having I/O becoming a bottleneck.\ntrain_dataset = train_dataset.prefetch(tf.data.AUTOTUNE)\nval_dataset   = val_dataset.prefetch(tf.data.AUTOTUNE)\n\n# Performing data augmentation inside the model improves dramatically the performances. From keras documentation:\n# With this option, preprocessing will happen on device, synchronously with the rest of the model execution, meaning that it will benefit from GPU acceleration\n\ndata_augmentation = tfk.Sequential(\n                            [\n                            tfkl.RandomFlip(mode = 'horizontal_and_vertical', seed = seed),\n                            tfkl.RandomTranslation(height_factor = (-0.5, 0.5), width_factor = (-0.5, 0.5), fill_mode = 'reflect', seed = seed), \n                            tfkl.RandomRotation(factor = 0.3, fill_mode = 'reflect', seed = seed),\n                            tfkl.RandomZoom(height_factor = (-0.3, 0.3), fill_mode = 'reflect', seed = seed), \n                            tfkl.RandomContrast(factor = 0.3, seed = seed)\n                            ]\n                            )","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Model metadata\ninput_shape = (256, 256, 3)\nepochs = 200\n\n# CNN model\n# Preprocessing + (Conv + ReLU + BatchNorm + MaxPool) x 5 + FC x 2\ndef build_model(input_shape):\n    \"\"\"\n    build_model generates the neural network model for the given input shape.\n    The model is made up by the following layers\n    - Input layer\n    - Augmentation layer\n    - EfficientNetB4 layers (without the dense part at the top)\n    - GlobalAveragePooling2D layer\n    - BatchNormalization layer\n    - Dense layers \n    \"\"\"\n    \n    input_layer               = tfkl.Input(shape = input_shape)\n    augmentation_layer        = data_augmentation(input_layer)\n    # noise_layer             = tfkl.GaussianNoise(stddev = 0.1)(augmentation_layer)\n    efficient_layer           = EfficientNetB4(weights = \"efficientnetb4_notop.h5\", include_top = False, input_tensor = augmentation_layer)\n    # Since we are performing transfer learning, the efficientnet layers are set to be non-trainable\n    efficient_layer.trainable = False\n    x                         = tfkl.GlobalAveragePooling2D()(efficient_layer.output)\n    x                         = tfkl.BatchNormalization()(x)\n    classifier_layer          = tfkl.Dense(units = 512, kernel_initializer = tfk.initializers.GlorotUniform(seed), activation = 'relu')(x)\n    classifier_layer          = tfkl.Dropout(0.3, seed = seed)(classifier_layer)\n    output_layer              = tfkl.Dense(units = 14, activation = 'softmax', kernel_initializer = tfk.initializers.GlorotUniform(seed))(classifier_layer)\n\n    # Connect input and output through the Model class\n    model = tfk.Model(inputs = input_layer, outputs = output_layer, name = 'model')\n    \n    # clr = tfa.optimizers.Triangular2CyclicalLearningRate(initial_learning_rate = 1e-4,\n    #                                                   maximal_learning_rate = 6e-2,\n    #                                                   step_size = 2 * 222)\n    \n    #f1 = tfa.metrics.F1Score(num_classes = 14, average = 'micro')\n    \n    # Compile the model\n    model.compile(loss      = tfk.losses.CategoricalCrossentropy(), \n                  optimizer = tfk.optimizers.Adam(learning_rate = 1e-2), \n                  metrics   = ['accuracy']\n                 )\n    \n    # Return the model\n    return model\n\nfrom datetime import datetime\n\ndef create_folders_and_callbacks(model_name):\n    \"\"\"\n    Callbacks definition: Save model checkpoints and EarlyStopping\n    \"\"\"\n\n    exps_dir = os.path.join('data_augmentation_experiments')\n    if not os.path.exists(exps_dir):\n        os.makedirs(exps_dir)\n\n    now = datetime.now().strftime('%b%d_%H-%M-%S')\n\n    exp_dir = os.path.join(exps_dir, model_name + '_' + str(now))\n    if not os.path.exists(exp_dir):\n        os.makedirs(exp_dir)\n      \n    callbacks = []\n\n    # Model checkpoint\n    ckpt_dir = os.path.join(exp_dir, 'ckpts')\n    if not os.path.exists(ckpt_dir):\n        os.makedirs(ckpt_dir)\n\n    ckpt_callback = tf.keras.callbacks.ModelCheckpoint(filepath          = os.path.join(ckpt_dir, 'cp.ckpt'), \n                                                     save_weights_only = False, # True to save only weights\n                                                     save_best_only    = True) # True to save only the best epoch \n    callbacks.append(ckpt_callback)\n\n    # Early Stopping\n    es_callback = tf.keras.callbacks.EarlyStopping(monitor = 'val_loss', mode = 'min', patience = 10, restore_best_weights = True)\n    callbacks.append(es_callback)\n\n    return callbacks\n\n# Build the model\nmodel = build_model(input_shape)\n\n# Create folders and callbacks and fit\ncallbacks = create_folders_and_callbacks(model_name = 'CNN_Aug_Transfer_Learning')\n\n# # Train the model\nhistory = model.fit(\n     x               = train_dataset,\n     epochs          = epochs,\n     validation_data = val_dataset,\n     callbacks       = callbacks).history\n\n# Save best epoch model\nmodel.save(\"data_augmentation_experiments/CNN_Aug_Transfer_Learning_Best\")\n\n# Plot the training\nplt.figure(figsize = (15, 5))\nplt.plot(history['loss'], label = 'Training', alpha = .8, color = '#ff7f0e')\nplt.plot(history['val_loss'], label = 'Validation', alpha = .8, color = '#4D61E2')\nplt.legend(loc = 'upper left')\nplt.title('Categorical Crossentropy')\nplt.grid(alpha = .3)\n\nplt.figure(figsize = (15,5))\nplt.plot(history['accuracy'], label = 'Training', alpha = .8, color = '#ff7f0e')\nplt.plot(history['val_accuracy'], label = 'Validation', alpha = .8, color = '#4D61E2')\nplt.legend(loc = 'upper left')\nplt.title('Accuracy')\nplt.grid(alpha = .3)\n\nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# EfficientNet network is made up by 7 blocks. During fine tuning, it is suggested to unfreeze whole layers inside a block. In the following lines of code the\n# 7th block gets complitely unfrozen, except fot the BatchNormalization layers, as suggested in the Keras documentation\n\nfor layer in model.layers[-36:]:\n    if not isinstance(layer, tfkl.BatchNormalization):\n        layer.trainable = True\n\nfor layer in model.layers:\n    print(\"{}: {}\".format(layer, layer.trainable))  \n    \n# Compile the model\nmodel.compile(loss      = tfk.losses.CategoricalCrossentropy(), \n              optimizer = tfk.optimizers.Adam(learning_rate=1e-4), \n              metrics   = ['accuracy'])\n\n# Create folders and callbacks and fit\ncallbacks = create_folders_and_callbacks(model_name = 'CNN_Aug_Fine_Tuning')\n\n#reduce_lr_callback = tf.keras.callbacks.ReduceLROnPlateau(monitor = 'val_loss', mode = 'min', factor = 0.2, patience = 5, min_lr = 1e-6)\n#aug_callbacks.append(reduce_lr_callback)\n\n# Train the model\nhistory_fine_tuning = model.fit(\n     x = train_dataset,\n     epochs = epochs,\n     validation_data = val_dataset,\n     callbacks = callbacks).history\n\n# Save best epoch model\nmodel.save(\"data_augmentation_experiments/CNN_Aug_Fine_Tuning_Best\")\n\n# Plot the training\nplt.figure(figsize=(15,5))\nplt.plot(history_fine_tuning['loss'], label='Training', alpha=.8, color='#ff7f0e')\nplt.plot(history_fine_tuning['val_loss'], label='Validation', alpha=.8, color='#4D61E2')\nplt.legend(loc='upper left')\nplt.title('Categorical Crossentropy')\nplt.grid(alpha=.3)\n\nplt.figure(figsize=(15,5))\nplt.plot(history_fine_tuning['accuracy'], label='Training', alpha=.8, color='#ff7f0e')\nplt.plot(history_fine_tuning['val_accuracy'], label='Validation', alpha=.8, color='#4D61E2')\nplt.legend(loc='upper left')\nplt.title('Accuracy')\nplt.grid(alpha=.3)\n\nplt.show()\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\n# Zip and download the work folder for the submission\n\n!zip -r fine_tuning.zip /kaggle/working","metadata":{"trusted":true},"execution_count":null,"outputs":[]}]}